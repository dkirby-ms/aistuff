# LLM-D Infrastructure Environment Configuration
# Copy this file to .env.dev and fill in your values

# HuggingFace Token (required)
# Create a token at: https://huggingface.co/settings/tokens
# The token needs read access to private models
HF_TOKEN=hf_your_token_here

# Optional: Custom token name for the Kubernetes secret
# HF_TOKEN_NAME=llm-d-hf-token

# Optional: Custom namespace for LLM-D deployment
# NAMESPACE=llmd

# Optional: Release name postfix for concurrent installs
# RELEASE_NAME_POSTFIX=inference-scheduling
